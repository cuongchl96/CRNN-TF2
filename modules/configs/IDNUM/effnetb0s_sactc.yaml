model_build:
  backbone: efficientnet-b0s
  sequence_modeling: abilstm
  model_head: attention
model_params:
  imgH: 32
  imgW: 200
  num_channels: 3
  max_len: 12
  hidden_size: 256
  character: 0123456789
transformer:
  num_heads: 8
  num_layers: 4
dataset:
  train_set: datasets/IDNum/idnum_train.tfrecords
  valid_set: datasets/IDNum/idnum_valid.tfrecords
  test_set: datasets/IDNum/idnum_test.tfrecords
data_augmentation:
  prob: 0.5
  augment_level: 5
training_params:
  optimizer: Adadelta
  num_epochs: 50
  batch_size: 32
  initial_lnr: 1.0
  num_warmup_steps: 0
  log_dir: checkpoints/Effnetb0s-abilstm256-attention-rgb-sactc
  log_interval: 1
  save_interval: 3200